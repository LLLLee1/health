import sys
sys.tracebacklimit = 0
import pandas as pd
import numpy as np
import joblib
import streamlit as st
import re
import jieba
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
import altair as alt
from wordcloud import WordCloud
import jieba.analyse

# 1. æ•°æ®åŠ è½½å™¨
class HealthDataLoader:
    def __init__(self, file_path="medical_claims_20250613_162711.csv"):
        self.file_path = file_path
        self.data = None
        
    def load_data(self):
        try:
            self.data = pd.read_csv(self.file_path)
            
            # ç¡®ä¿æ•°æ®å®Œæ•´æ€§
            if 'credibility' not in self.data.columns:
                raise ValueError("æ•°æ®é›†ç¼ºå°‘'credibility'åˆ—")
                
            # æ·»åŠ å¥åº·å£°æ˜ç±»åˆ«
            self.data['category'] = self.data['claim'].apply(self.classify_claim)
            
            st.success(f"âœ… æˆåŠŸåŠ è½½æ•°æ®é›†: {len(self.data)}æ¡å¥åº·å£°æ˜")
            return True
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return False
        
    def classify_claim(self, claim):
        """è‡ªåŠ¨åˆ†ç±»å¥åº·å£°æ˜åˆ°å¥åº·é¢†åŸŸ"""
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»
        categories = {
            'å¿ƒè¡€ç®¡å¥åº·': ['å¿ƒè„', 'è¡€å‹', 'èƒ†å›ºé†‡', 'è¡€è„‚', 'ä¸­é£'],
            'è¥å…»é¥®é£Ÿ': ['é¥®é£Ÿ', 'è¥å…»', 'ç»´ç”Ÿç´ ', 'è›‹ç™½è´¨', 'è„‚è‚ª', 'ç¢³æ°´', 'çŸ¿ç‰©è´¨'],
            'è¿åŠ¨å¥èº«': ['è¿åŠ¨', 'é”»ç‚¼', 'å¥èº«', 'æœ‰æ°§', 'è‚Œè‚‰', 'åŠ›é‡'],
            'å¿ƒç†å¥åº·': ['æŠ‘éƒ', 'ç„¦è™‘', 'å‹åŠ›', 'æƒ…ç»ª', 'ç¡çœ ', 'å¿ƒç†'],
            'æ…¢æ€§ç—…ç®¡ç†': ['ç³–å°¿ç—…', 'é«˜è¡€å‹', 'å…³èŠ‚ç‚', 'ç®¡ç†', 'æ§åˆ¶', 'æ…¢æ€§'],
            'ç™Œç—‡é˜²æ²»': ['ç™Œç—‡', 'è‚¿ç˜¤', 'æŠ—ç™Œ', 'è½¬ç§»', 'åŒ–ç–—'],
            'ä¼ ç»ŸåŒ»å­¦': ['ä¸­åŒ»', 'è‰è¯', 'é’ˆç¸', 'ç»ç»œ', 'å¹³è¡¡', 'å¯’çƒ­'],
            'å„¿ç§‘å¥åº·': ['å„¿ç«¥', 'å‘è‚²', 'ç–«è‹—', 'å–‚å…»', 'æ—©æ•™'],
            'è€å¹´å¥åº·': ['è€å¹´', 'è€é¾„', 'é€€ä¼‘', 'å…³èŠ‚', 'è®¤çŸ¥'],
        }
        
        for category, keywords in categories.items():
            if any(keyword in claim for keyword in keywords):
                return category
        
        return 'å…¶ä»–'
    
    def get_categories(self):
        """è·å–æ•°æ®ä¸­çš„å¥åº·å£°æ˜ç±»åˆ«"""
        if self.data is not None and 'category' in self.data.columns:
            return self.data['category'].value_counts()
        return None
        
    def get_sample_data(self, n=5):
        return self.data.sample(n)[['claim', 'credibility', 'category']]

# 2. ä¸“ä¸šç‰¹å¾å·¥ç¨‹ï¼ˆç»“åˆåŒ»å­¦çŸ¥è¯†ï¼‰
class HealthFeatureEngineer(BaseEstimator, TransformerMixin):
    def __init__(self):
        # å¯ä¿¡åº¦ä¿¡å·ï¼ˆåŒ»å­¦ä¸“ä¸šæœ¯è¯­ï¼‰
        self.reliable_terms = [
            'ä¸´åºŠè¯•éªŒ', 'å¾ªè¯åŒ»å­¦', 'åŒç›²ç ”ç©¶', 'éšæœºå¯¹ç…§è¯•éªŒ', 
            'ç³»ç»Ÿæ€§è¯„ä»·', 'å­¦æœ¯æœŸåˆŠ', 'åŒ»å­¦æŠ¥å‘Š', 'ç—…ç†ç ”ç©¶',
            'è¯ç†ä½œç”¨', 'ä¸´åºŠè§‚å¯Ÿ', 'æµè¡Œç—…å­¦ç ”ç©¶', 'å¤šä¸­å¿ƒç ”ç©¶'
        ]
        
        # é£é™©ä¿¡å·ï¼ˆä¼ªç§‘å­¦ç‰¹å¾ï¼‰
        self.warning_signals = [
            'ç§˜æ–¹', 'å¥‡è¿¹', 'å½»åº•æ²»æ„ˆ', 'æ°¸ä¸å¤å‘', 'åŒ…æ²»ç™¾ç—…',
            'ä¸“å®¶ä¸è¯´', 'åŒ»é™¢éšè—', 'ç«‹å³è§æ•ˆ', 'ç«‹å³è½¬å‘', 'æ”¿åºœéšç’',
            'æ•ˆæœæƒŠäºº', 'ç¥å¥‡ç–—æ•ˆ', 'ç¥–æå®¢æ—¶é—´ä¼ ç§˜æ–¹', 'ç»å¯¹å®‰å…¨', 'çº¯å¤©ç„¶'
        ]
        
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        """æå–é«˜çº§å¥åº·å£°æ˜ç‰¹å¾"""
        features = []
        
        for text in X:
            # åŸºç¡€æ–‡æœ¬ç‰¹å¾
            text_length = len(text)
            char_count = len(re.findall(r'[A-Za-z0-9]', text))
            zh_char_count = len(re.findall(r'[\u4e00-\u9fff]', text))
            
            # å¯ä¿¡åº¦ç‰¹å¾
            reliable_count = sum(1 for term in self.reliable_terms if term in text)
            warning_count = sum(1 for signal in self.warning_signals if signal in text)
            
            # æƒ…æ„Ÿç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
            positive_terms = ['æœ‰ç›Š', 'æ¨è', 'ä¿ƒè¿›', 'æ”¹å–„', 'æå‡', 'ä¿æŠ¤']
            negative_terms = ['æœ‰å®³', 'é¿å…', 'é£é™©', 'å‰¯ä½œç”¨', 'å±é™©', 'ç¦å¿Œ']
            positive_score = sum(1 for term in positive_terms if term in text)
            negative_score = sum(1 for term in negative_terms if term in text)
            
            # æ•°å€¼ç‰¹å¾
            has_number = 1 if re.search(r'\d+', text) else 0
            percent_count = text.count('%')
            
            # ç»“æ„ç‰¹å¾
            sentence_count = text.count('ã€‚') + text.count('ï¼') + text.count('ï¼Ÿ') + 1
            
            # ç»„åˆç‰¹å¾
            feature_vec = [
                text_length,
                char_count,
                zh_char_count,
                reliable_count,
                warning_count,
                positive_score,
                negative_score,
                has_number,
                percent_count,
                sentence_count
            ]
            features.append(feature_vec)
            
        return np.array(features)

# 3. åŒæ¨¡å‹è®­ç»ƒç®¡é“ï¼ˆæ–‡æœ¬+ç‰¹å¾èåˆï¼‰
class HealthKnowledgePipeline:
    def __init__(self, data):
        self.data = data
        self.model = None
        self.vectorizer = None
        self.feature_engineer = HealthFeatureEngineer()
        self.performance = None
        
    def train_model(self):
        """è®­ç»ƒä¸“ä¸šå¥åº·çŸ¥è¯†æ¨¡å‹"""
        # å‡†å¤‡æ•°æ®
        X = self.data['claim']
        y = self.data['credibility'].apply(lambda x: 1 if x > 0.7 else 0)
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # åˆ›å»ºæ¨¡å‹ç®¡é“
        self.model = Pipeline([
            ('features', self.feature_engineer),
            ('classifier', GradientBoostingClassifier(
                n_estimators=200,
                learning_rate=0.05,
                max_depth=5,
                subsample=0.8,
                random_state=42
            ))
        ])
        
        # è®­ç»ƒæ¨¡å‹
        with st.spinner("æ¨¡å‹è®­ç»ƒä¸­ï¼Œè¯·ç¨å€™..."):
            self.model.fit(X_train, y_train)
            
            # è¯„ä¼°æ¨¡å‹
            y_pred = self.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred)
            
            # æ€§èƒ½æŒ‡æ ‡
            self.performance = {
                'accuracy': accuracy,
                'classification_report': report,
                'confusion_matrix': confusion_matrix(y_test, y_pred)
            }
            
            # ä¿å­˜æ¨¡å‹
            joblib.dump(self.model, 'health_knowledge_model.pkl')
            st.success("æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶ä¿å­˜ï¼")
            st.write(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.2f}")
            
        return self.performance
    
    def visualize_performance(self):
        """å¯è§†åŒ–æ¨¡å‹æ€§èƒ½"""
        if not self.performance:
            return
            
        cm = self.performance['confusion_matrix']
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['ä¸å¯ä¿¡', 'å¯ä¿¡'], 
                   yticklabels=['ä¸å¯ä¿¡', 'å¯ä¿¡'])
        ax.set_xlabel('é¢„æµ‹')
        ax.set_ylabel('çœŸå®')
        ax.set_title('æ··æ·†çŸ©é˜µ')
        st.pyplot(fig)
        
        st.text("åˆ†ç±»æŠ¥å‘Š:")
        st.text(self.performance['classification_report'])

# 4. ä¸“ä¸šè¯„ä¼°æŠ¥å‘Šç”Ÿæˆ
class HealthCredibilityReport:
    def __init__(self):
        self.explanation_db = {
            "reliable_terms": "åŒ…å«å¯ä¿¡åº¦ä¿¡å·: å­¦æœ¯ç ”ç©¶ã€ä¸´åºŠè¯•éªŒç­‰ä¸“ä¸šè¯æ±‡",
            "warning_signals": "æ£€æµ‹åˆ°é£é™©ä¿¡å·: ç§˜æ–¹ã€å¥‡è¿¹ç­‰ä¼ªç§‘å­¦è¯æ±‡",
            "evidence_based": "åŒ…å«æ•°æ®æ”¯æ’‘: æœ‰å…·ä½“æ•°å€¼æˆ–ç™¾åˆ†æ¯”",
            "unrealistic": "æ£€æµ‹åˆ°ä¸åˆ‡å®é™…çš„æ‰¿è¯º: å½»åº•æ²»æ„ˆã€æ°¸ä¸å¤å‘ç­‰"
        }
        self.topic_keywords = {
            "å¿ƒè¡€ç®¡å¥åº·": ["å¿ƒè„", "è¡€å‹", "è¡€è„‚", "èƒ†å›ºé†‡", "ä¸­é£"],
            "è¥å…»é¥®é£Ÿ": ["é¥®é£Ÿ", "è¥å…»", "ç»´ç”Ÿç´ ", "è›‹ç™½è´¨", "è„‚è‚ª"],
            "è¿åŠ¨å¥èº«": ["è¿åŠ¨", "é”»ç‚¼", "å¥èº«", "æœ‰æ°§", "è‚Œè‚‰"],
            "å¿ƒç†å¥åº·": ["å‹åŠ›", "æŠ‘éƒ", "ç„¦è™‘", "ç¡çœ ", "æå®¢æ—¶é—´æƒ…ç»ª"],
            "æ…¢æ€§ç—…ç®¡ç†": ["ç³–å°¿ç—…", "é«˜è¡€å‹", "å…³èŠ‚ç‚", "ç®¡ç†", "æ§åˆ¶"]
        }
        
    def identify_topic(self, claim):
        """è¯†åˆ«å¥åº·å£°æ˜çš„ä¸»é¢˜é¢†åŸŸ"""
        for topic, keywords in self.topic_keywords.items():
            if any(keyword in claim for keyword in keywords):
                return topic
        return "å…¶ä»–å¥åº·é¢†åŸŸ"
        
    def generate_report(self, claim, prediction, explanation, credibility_score):
        """ç”Ÿæˆä¸“ä¸šå¥åº·å£°æ˜è¯„ä¼°æŠ¥å‘Š"""
        # è¯†åˆ«ä¸»é¢˜
        health_topic = self.identify_topic(claim)
        
        # å¯ä¿¡åº¦ç­‰çº§
        risk_level = "ä½é£é™©"
        risk_color = "green"
        risk_explanation = "è¯¥å£°æ˜å¯ä¿¡åº¦é«˜ï¼Œå¯ä½œä¸ºå‚è€ƒ"
        if credibility_score < 30:
            risk_level = "é«˜é£é™©"
            risk_color = "red"
            risk_explanation = "é«˜é£é™©å£°æ˜ï¼Œè¯·è°¨æ…å¯¹å¾…å¹¶æ ¸å®æ¥æº"
        elif credibility_score < 70:
            risk_level = "ä¸­ç­‰é£é™©"
            risk_color = "orange"
            risk_explanation = "ä¸­ç­‰é£é™©ï¼Œéœ€è¿›ä¸€æ­¥éªŒè¯ä¿¡æ¯æ¥æº"
        
        # å…³é”®å½±å“å› ç´ 
        key_factors = []
        for factor, desc in self.explanation_db.items():
            if factor in explanation:
                key_factors.append(desc)
        
        # åŒ»ç–—ä¸“ä¸šå»ºè®®
        recommendations = []
        if prediction == 1:  # å¯ä¿¡
            if credibility_score > 90:
                recommendations.append(f"âœ… å¯ä¿¡åº¦æé«˜ ({credibility_score}åˆ†)ï¼Œå¯ä½œä¸º{health_topic}é¢†åŸŸçš„å¯é å‚è€ƒ")
            else:
                recommendations.append(f"âš ï¸ ä¿¡æ¯åŸºæœ¬å¯ä¿¡ ({credibility_score}åˆ†)ï¼Œå»ºè®®ç¡®è®¤{health_topic}é¢†åŸŸçš„æœ€æ–°åŒ»å­¦æŒ‡å—")
        else:  # ä¸å¯ä¿¡
            recommendations.append(f"âŒ å¯ä¿¡åº¦ä¸è¶³ ({credibility_score}åˆ†)ï¼Œè¯·å‹¿ç›´æ¥é‡‡çº³")
            recommendations.append(f"ğŸ” å»ºè®®æŸ¥è¯¢{health_topic}é¢†åŸŸçš„ä¸“ä¸šåŒ»å­¦èµ„æº")
        
        return {
            "claim": claim,
            "credibility_score": credibility_score,
            "risk_level": risk_level,
            "risk_color": risk_color,
            "risk_explanation": risk_explanation,
            "prediction": "å¯ä¿¡åº¦é«˜" if prediction == 1 else "å­˜åœ¨é£é™©",
            "health_topic": health_topic,
            "key_factors": key_factors,
            "recommendations": recommendations,
            "explanation": explanation
        }
    
    def display_report(self, report):
        """åœ¨Streamlitä¸­æ˜¾ç¤ºä¸“ä¸šæŠ¥å‘Š"""
        st.subheader("å¥åº·å£°æ˜è¯„ä¼°æŠ¥å‘Š")
        
        # æ•´ä½“è¯„åˆ†
        col1, col2, col3 = st.columns([1,2,1])
        with col1:
            st.metric("å¯ä¿¡åº¦è¯„åˆ†", f"{report['credibility_score']}åˆ†")
            st.markdown(
                f"<div style='background-color:{report['risk_color']};padding:10px;border-radius:5px;'>"
                f"<strong>é£é™©ç­‰çº§:</strong> {report['risk_level']}</div>",
                unsafe_allow_html=True
            )
        
        # å¥åº·ä¸»é¢˜å’Œé£é™©è§£é‡Š
        with col2:
            st.subheader("ä¸»é¢˜é¢†åŸŸ")
            st.markdown(f"**{report['health_topic']}**")
            
            st.subheader("é£é™©è¯´æ˜")
            st.info(f"{report['risk_explanation']}")
        
        # å£°æ˜æ˜¾ç¤º
        with col3:
            st.caption("è¢«è¯„ä¼°å£°æ˜")
            st.info(f"**{report['claim']}**")
        
        st.divider()
        
        # å…³é”®å› ç´ 
        with st.expander("ğŸ” å½±å“å› ç´ åˆ†æ", expanded=True):
            for factor in report.get('key_factors', []):
                st.markdown(f"- {factor}")
            
            # ç‰¹å¾è¯¦æƒ…
            if 'explanation' in report and 'ç‰¹å¾æå®¢æ—¶é—´å€¼' in report['explanation']:
                st.subheader("æŠ€æœ¯ç‰¹å¾åˆ†æ")
                features = [
                    "æ–‡æœ¬é•¿åº¦", "è‹±æ–‡å­—ç¬¦æ•°", "ä¸­æ–‡å­—ç¬¦æ•°", "å¯ä¿¡æœ¯è¯­æ•°", 
                    "é£é™©ä¿¡å·æ•°", "æ­£é¢æƒ…æ„Ÿè¯", "è´Ÿé¢æƒ…æ„Ÿè¯", "åŒ…å«æ•°å­—", 
                    "ç™¾åˆ†æ¯”æ•°é‡", "å¥å­æ•°é‡"
                ]
                for i, feat in enumerate(features):
                    value = report['explanation']['ç‰¹å¾å€¼'][i]
                    st.markdown(f"- **{feat}**: {value}")
        
        # å»ºè®®ä¸è§£é‡Š
        st.subheader("ä¸“ä¸šå»ºè®®")
        rec_cols = st.columns(2)
        for i, rec in enumerate(report.get('recommendations', [])):
            with rec_cols[i % 2]:
                if rec.startswith("âœ…"):
                    st.success(rec)
                elif rec.startswith("âš ï¸"):
                    st.warning(rec)
                else:
                    st.error(rec)
        
        # ç›¸å…³èµ„æº
        with st.expander("ğŸ©º ä¸»é¢˜å¥åº·èµ„æº"):
            self.display_health_resources(report['health_topic'])
    
    def display_health_resources(self, topic):
        """æ˜¾ç¤ºä¸»é¢˜ç›¸å…³å¥åº·èµ„æº"""
        resources = {
            "å¿ƒè¡€ç®¡å¥åº·": [
                ("ä¸­å›½å¿ƒè¡€ç®¡å¥åº·è”ç›Ÿ", "https://www.csca.org.cn"),
                ("ç¾å›½å¿ƒè„åä¼š", "https://www.heart.org"),
                ("å¿ƒè„å¥åº·æ‰‹å†Œ", "https://www.nhlbi.nih.gov/health-topics/all-publications-and-resources")
            ],
            "è¥å…»é¥®é£Ÿ": [
                ("ä¸­å›½è¥å…»å­¦ä¼š", "https://www.cnsoc.org"),
                ("è¥å…»ä¸é¥®é£Ÿå­¦ä¼š", "https://www.eatright.org"),
                ("å¥åº·é¥®é£ŸæŒ‡å—", "https://www.who.int/publications-detail-redirect/9789240063457")
            ],
            "è¿åŠ¨å¥èº«": [
                ("ä¸­å›½ä½“è‚²ç§‘å­¦å­¦ä¼š", "http://www.csss.cn"),
                ("ç¾å›½è¿åŠ¨åŒ»å­¦ä¼š", "https://www.acsm.org"),
                ("è¿åŠ¨å¤„æ–¹æŒ‡å—", "https://www.health.gov/paguidelines")
            ],
            "å¿ƒç†å¥åº·": [
                ("ä¸­å›½å¿ƒç†å«ç”Ÿåä¼š", "http://www.camh.org.cn"),
                ("ä¸–ç•Œå¿ƒç†å«ç”Ÿè”ç›Ÿ", "https://wfme.org"),
                ("å¿ƒç†å¥åº·è‡ªåŠ©æ‰‹å†Œ", "https://www.who.int/publications-detail-redirect/9789240031029")
            ],
            "æ…¢æ€§ç—…ç®¡ç†": [
                ("ä¸­å›½æ…¢æ€§ç—…ç®¡ç†ç½‘", "http://www.chronicdisease.org.cn"),
                ("ç¾å›½æ…¢æ€§ç—…ç®¡ç†åä¼š", "https://www.pcpcc.org"),
                ("æ…¢æ€§ç—…è‡ªæˆ‘ç®¡ç†æŒ‡å—", "https://www.cdc.gov/chronicdisease/index.htm")
            ]
        }
        
        if topic in resources:
            for name, url in resources[topic]:
                st.markdown(f"ğŸ”— [{name}]({url})")
        else:
            st.info("æš‚æ— ç›¸å…³ä¸“ä¸šèµ„æºï¼Œè¯·æŸ¥é˜…é€šç”¨åŒ»å­¦èµ„æº")

# 5. é«˜çº§åŠŸèƒ½æ‰©å±•
class HealthSystemExtensions:
    def __init__(self, data):
        self.data = data
        self.vectorizer = TfidfVectorizer(max_features=1000)
        self.claim_matrix = self.vectorizer.fit_transform(data['claim'])
        
    def health_risk_assessment(self):
        """å¤šå£°æ˜å¥åº·é£é™©è¯„ä¼°"""
        st.subheader("ğŸ“ˆ ç»¼åˆå¥åº·é£é™©è¯„ä¼°")
        st.info("è¾“å…¥å¤šä»½å¥åº·ä¿¡æ¯ï¼Œè¯„ä¼°æ•´ä½“é£é™©")
        
        claims = st.text_area(
            "è¾“å…¥å¤šä¸ªå¥åº·å£°æ˜ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
            height=150,
            placeholder="ä¾‹å¦‚:\næ¯å¤©å–çº¢é…’æœ‰ç›Šå¿ƒè„å¥åº·\né«˜è„‚è‚ªé¥®é£Ÿä¼šå¢åŠ å¿ƒè„ç—…é£é™©\nç»´ç”Ÿç´ Cå¯ä»¥é¢„é˜²æ„Ÿå†’",
            key="multi_claims"
        )
        
        if st.button("è¯„ä¼°æ•´ä½“é£é™©"):
            if not claims.strip():
                st.warning("è¯·è¾“å…¥å¥åº·å£°æ˜å†…å®¹")
                return
                
            claim_list = [c.strip() for c in claims.split("\n") if c.strip()]
            
            # è¯„ä¼°æ¯æ¡å£°æ˜çš„é£é™©
            risks = []
            try:
                model = joblib.load('health_knowledge_model.pkl')
                for claim in claim_list:
                    prediction_proba = model.predict_proba([claim])[0]
                    risk_score = prediction_proba[0] * 100  # ä¸å¯ä¿¡çš„æ¦‚ç‡ä½œä¸ºé£é™©å€¼
                    risks.append(risk_score)
                
                # æ€»ä½“é£é™©è¯„ä¼°
                avg_risk = np.mean(risks)
                max_risk = max(risks)
                
                st.subheader("æ•´ä½“é£é™©è¯„ä¼°ç»“æœ")
                
                col1, col2 = st.columns(2)
                col1.metric("å¹³å‡é£é™©å€¼", f"{avg_risk:.1f}åˆ†")
                col2.metric("æœ€é«˜é£é™©å£°æ˜", f"{max_risk:.1æå®¢æ—¶é—´f}åˆ†")
                
                # é£é™©å¯è§†åŒ–
                risk_data = pd.DataFrame({
                    'å£°æ˜': [f"å£°æ˜{i+1}" for i in range(len(risks))],
                    'é£é™©å€¼': risks
                })
                
                # æ·»åŠ é£é™©ç±»åˆ«åˆ—
                risk_data['é£é™©ç±»åˆ«'] = risk_data['é£é™©å€¼'].apply(
                    lambda x: 'é«˜é£é™©' if x > 70 
                    else 'ä¸­é£é™©' if x > 40 
                    else 'ä½é£é™©'
                )
                
                risk_chart = alt.Chart(risk_data).mark_bar().encode(
                    x=alt.X('å£°æ˜:N', sort='-y'),
                    y=alt.Y('é£é™©å€¼:Q', title='é£é™©å€¼', scale=alt.Scale(domain=[0, 100])),
                    color=alt.Color('é£é™©ç±»åˆ«:N', scale=alt.Scale(
                        domain=['ä½é£é™©', 'ä¸­é£é™©', 'é«˜é£é™©'],
                        range=['green', 'orange', 'red']
                    )),
                    tooltip=['å£°æ˜', 'é£é™©å€¼', 'é£é™©ç±»åˆ«']
                ).properties(
                    width=600,
                    height=300
                )
                st.altair_chart(risk_chart, use_container_width=True)
                
                # é£é™©å£°æ˜åˆ†æ
                max_risk_index = np.argmax(risks)
                st.warning(f"**æœ€é«˜é£é™©å£°æ˜**: {claim_list[max_risk_index]} (é£é™©å€¼: {risks[max_risk_index]:.1f}åˆ†)")
                
                # å­˜å‚¨è¯„ä¼°ç»“æœ
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
                st.session_state.setdefault('risk_history', []).append({
                    "timestamp": timestamp,
                    "claims": claim_list,
                    "avg_risk": avg_risk,
                    "max_risk": max_risk
                })
                
            except Exception as e:
                st.error(f"é£é™©è¯„ä¼°å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºå†å²è¯„ä¼°è®°å½•
        if 'risk_history' in st.session_state and st.session_state['risk_history']:
            st.subheader("å†å²è¯„ä¼°è®°å½•")
            history_df = pd.DataFrame(st.session_state['risk_history'])
            st.dataframe(history_df.sort_values('timestamp', ascending=False).head(5))
    
    def health_quiz(self):
        """å¥åº·çŸ¥è¯†å°æµ‹è¯•"""
        st.subheader("ğŸ§ª å¥åº·çŸ¥è¯†å°æµ‹éªŒ")
        st.info("æµ‹è¯•æ‚¨çš„å¥åº·çŸ¥è¯†æ°´å¹³ï¼Œè¯†åˆ«ä¼ªç§‘å­¦ä¿¡æ¯")
        
        # ä»æ•°æ®é›†ä¸­é€‰æ‹©é—®é¢˜
        quiz_questions = self.data.sample(3)[['claim', 'credibility', 'explanation']].reset_index(drop=True)
        
        if st.button("ç”Ÿæˆæ–°æµ‹è¯•"):
            st.session_state.quiz_questions = quiz_questions
            st.session_state.user_answers = [None] * len(quiz_questions)
            st.session_state.quiz_submitted = False
        
        if 'quiz_questions' not in st.session_state:
            st.write("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆæµ‹è¯•é¢˜")
            return
            
        questions = st.session_state.quiz_questions
        user_answers = st.session_state.user_answers
        submitted = st.session_state.quiz_submitted
        
        for i in range(len(questions)):
            st.subheader(f"é—®é¢˜ {i+1}")
            # å®‰å…¨è®¿é—®è¡Œæ•°æ®
            row = questions.iloc[i]
            claim = row['claim']
            st.markdown(f"**å¥åº·å£°æ˜ï¼š** {claim}")
            
            if not submitted:
                options = ['éå¸¸å¯ä¿¡', 'æ¯”è¾ƒå¯ä¿¡', 'ä¸ç¡®å®š', 'ä¸å¤ªå¯ä¿¡', 'éå¸¸ä¸å¯ä¿¡']
                user_answers[i] = st.radio(
                    f"æ‚¨è®¤ä¸ºè¿™ä¸ªå£°æ˜çš„å¯ä¿¡åº¦å¦‚ä½•ï¼Ÿ",
                    options,
                    key=f"quiz_q{i}"
                )
            else:
                credibility = row['credibility']
                correct_answer = 'éå¸¸å¯ä¿¡' if credibility > 0.8 else 'æ¯”è¾ƒå¯ä¿¡' if credibility > 0.6 else 'ä¸å¤ªå¯ä¿¡' if credibility > 0.4 else 'éå¸¸ä¸å¯ä¿¡'
                user_answer = user_answers[i]
                
                st.info(f"æ‚¨çš„é€‰æ‹©: **{user_answer}**")
                if user_answer == correct_answer:
                    st.success(f"âœ… æ­£ç¡®ï¼å®é™…å¯ä¿¡åº¦: {credibility:.2f}")
                else:
                    st.error(f"âŒ é”™è¯¯ï¼Œæ­£ç¡®é€‰é¡¹æ˜¯: **{correct_answer}** (å®é™…å¯ä¿¡åº¦: {credibility:.2f})")
                
                with st.expander("æŸ¥çœ‹è§£é‡Š"):
                    explanation = row['explanation']
                    st.markdown(f"**ç§‘å­¦è§£é‡Šï¼š** {explanation}")
        
        if not submitted:
            if st.button("æäº¤æµ‹è¯•", type="primary"):
                st.session_state.quiz_submitted = True
                st.experimental_rerun()
        else:
            # è®¡ç®—å¾—åˆ†
            correct_count = 0
            for i in range(len(questions)):
                credibility = questions.iloc[i]['credibility']
                correct_answer = 'éå¸¸å¯ä¿¡' if credibility > 0.8 else 'æ¯”è¾ƒå¯ä¿¡' if credibility > 0.6 else 'ä¸å¤ªå¯ä¿¡' if credibility > 0.4 else 'éå¸¸ä¸å¯ä¿¡'
                if user_answers[i] == correct_answer:
                    correct_count += 1
            
            score = correct_count / len(questions) * 100
            
            st.success(f"ğŸ“ æµ‹è¯•å®Œæˆï¼æ‚¨çš„å¾—åˆ†: **{score:.0f}åˆ†**")
            if score >= 80:
                st.balloons()
                st.success("ğŸ‰ ä¼˜ç§€ï¼æ‚¨å¯¹å¥åº·çŸ¥è¯†æœ‰å¾ˆé«˜çš„è¾¨åˆ«èƒ½åŠ›")
            elif score >= 60:
                st.info("ğŸ‘ è‰¯å¥½ï¼æ‚¨å¯¹å¥åº·ä¿¡æ¯æœ‰ä¸€å®šåˆ¤æ–­èƒ½åŠ›")
            else:
                st.warning("ğŸ’¡ ç»§ç»­åŠªåŠ›ï¼å»ºè®®å¤šå­¦ä¹ å¥åº·çŸ¥è¯†")

# 6. Streamlitåº”ç”¨ä¸»å‡½æ•°
def main_health_app():
    st.set_page_config(
        page_title="ç§‘å­¦å¥åº·çŸ¥è¯†å¯ä¿¡åº¦åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ©º",
        layout="wide",
        initial_sidebar_state="expanded",
        menu_items={
            'Get Help': 'https://www.example.com/help',
            'Report a bug': "https://www.example.com/bug",
            'About': "# ç§‘å­¦å¥åº·çŸ¥è¯†åˆ†æç³»ç»Ÿ v2.4"
        }
    )
    
    st.title("ğŸ©º ç§‘å­¦å¥åº·çŸ¥è¯†å¯ä¿¡åº¦åˆ†æç³»ç»Ÿ")
    st.caption("åŸºäºä¸“ä¸šå¥åº·å£°æ˜çš„å¯ä¿¡åº¦åˆ†æä¸çŸ¥è¯†å‘ç°")
    
    # åˆå§‹åŒ–çŠ¶æ€
    st.session_state.setdefault('history', [])
    st.session_state.setdefault('health_topic', 'å¿ƒè¡€ç®¡å¥åº·')
    
    # é¡µé¢é€‰æ‹©å™¨
    page = st.sidebar.selectbox(
        "åŠŸèƒ½èœå•",
        ["å¥åº·å£°æ˜åˆ†æ", "é£é™©è¯„ä¼°", "å¥åº·å°æµ‹è¯•"],
        index=0
    )
    
    # åŠ è½½æ•°æ®
    data_loader = HealthDataLoader()
    if not data_loader.load_data():
        return
    
    # é¡¶éƒ¨å±•ç¤ºå¥åº·ä¸»é¢˜åˆ†å¸ƒ
    category_counts = data_loader.get_categories()
    if category_counts is not None:
        with st.container():
            st.subheader("å¥åº·ä¸»é¢˜åˆ†å¸ƒ")
            st.bar_chart(category_counts)
    
    # æ˜¾ç¤ºæ•°æ®é›†æ ·æœ¬
    with st.expander("æ•°æ®é›†æ ·æœ¬", expanded=False):
        st.dataframe(data_loader.get_sample_data(3))
    
    # åŠŸèƒ½é¡µé¢è·¯ç”±
    if page == "å¥åº·å£°æ˜åˆ†æ":
        render_analysis_page(data_loader.data)
    elif page == "é£é™©è¯„ä¼°":
        render_risk_assessment_page(data_loader.data)
    elif page == "å¥åº·å°æµ‹è¯•":
        render_quiz_page(data_loader.data)
    
    # ä¾§è¾¹æ åŒºåŸŸ
    with st.sidebar:
        st.divider()
        st.subheader("å†å²è®°å½•")
        if st.session_state.history:
            for i, item in enumerate(st.session_state.history[-3:]):
                risk_color = "green" if item['score'] > 70 else "orange" if item['score'] > 30 else "red"
                with st.expander(f"è®°å½• {i+1} ({item['score']}åˆ†)", expanded=False):
                    st.markdown(f"**å£°æ˜:** {item['claim']}")
                    st.markdown(f"**æ—¶é—´:** {item['time']}")
                    st.markdown(f"**è¯„ä¼°:** <span style='color:{risk_color};'>{item['score']}åˆ†</span>", 
                               unsafe_allow_html=True)
        else:
            st.info("æš‚æ— åˆ†æå†å²")
        
        st.divider()
        st.subheader("æƒå¨åŒ»å­¦èµ„æº")
        st.markdown("- [ä¸–ç•Œå«ç”Ÿç»„ç»‡ (WHO)](https://www.who.int)")
        st.markdown("- [ä¸­å›½å›½å®¶å«å¥å§”](http://www.nhc.gov.cn)")
        st.markdown("- [ç¾å›½ç–¾æ§ä¸­å¿ƒ (CDC)](https://www.cdc.gov)")
        st.markdown("- [PubMedåŒ»å­¦æ–‡çŒ®](https://pubmed.ncbi.nlm.nih.gov)")
        
        st.divider()
        st.caption("ç³»ç»Ÿç‰ˆæœ¬: 2.4 | æ›´æ–°æ—¥æœŸ: 2025-06-15")

def render_analysis_page(data):
    """å¥åº·å£°æ˜åˆ†æé¡µé¢"""
    st.header("ğŸ” å¥åº·å£°æ˜åˆ†æ")
    
    # æ¨¡å‹è®­ç»ƒéƒ¨åˆ†
    if st.button("è®­ç»ƒ/æ›´æ–°æ¨¡å‹", type="primary"):
        model_pipeline = HealthKnowledgePipeline(data)
        performance = model_pipeline.train_model()
        
        # å¯è§†åŒ–æ¨¡å‹æ€§èƒ½
        with st.expander("æ¨¡å‹æ€§èƒ½è¯¦æƒ…"):
            model_pipeline.visualize_performance()
    
    # å£°æ˜åˆ†æç•Œé¢
    health_claim = st.text_area(
        "è¾“å…¥éœ€è¦åˆ†æçš„åŒ»å­¦å£°æ˜:", 
        placeholder="ä¾‹å¦‚ï¼šæ¯å¤©é¥®ç”¨ç»¿èŒ¶å¯ä»¥é™ä½å¿ƒè„ç—…é£é™©30%",
        height=120
    )
    
    if st.button("åˆ†æå¯ä¿¡åº¦", type="secondary"):
        if not health_claim:
            st.warning("è¯·è¾“å…¥å¥åº·å£°æ˜å†…å®¹")
            return
            
        try:
            model = joblib.load('health_knowledge_model.pkl')
            report_gen = HealthCredibilityReport()
            
            # è·å–ç‰¹å¾å€¼
            feature_engineer = model.named_steps['features']
            feature_values = feature_engineer.transform([health_claim])[0]
            
            # é¢„æµ‹å¯ä¿¡åº¦
            prediction = model.predict([health_claim])[0]
            prediction_proba = model.predict_proba([health_claim])[0]
            credibility_score = prediction_proba[1] * 100
            
            # ç”ŸæˆæŠ¥å‘Š
            report = report_gen.generate_report(
                claim=health_claim,
                prediction=prediction,
                explanation={"ç‰¹å¾å€¼": feature_values.tolist()},
                credibility_score=round(credibility_score, 1)
            )
            
            # æ˜¾ç¤ºæŠ¥å‘Š
            report_gen.display_report(report)
                
            # ä¿å­˜å†å²
            st.session_state.history.append({
                "time": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "claim": health_claim[:100] + "..." if len(health_claim) > 100 else healthæå®¢æ—¶é—´_claim,
                "score": round(credibility_score, 1)
            })
                
        except Exception as e:
            st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            st.error("è¯·ç¡®ä¿æ•°æ®é›†å’Œæ¨¡å‹å·²å‡†å¤‡å°±ç»ª")

def render_risk_assessment_page(data):
    """å¤šå£°æ˜é£é™©è¯„ä¼°é¡µé¢"""
    st.header("ğŸ“ˆ ç»¼åˆå¥åº·é£é™©è¯„ä¼°")
    extensions = HealthSystemExtensions(data)
    extensions.health_risk_assessment()

def render_quiz_page(data):
    """å¥åº·çŸ¥è¯†å°æµ‹è¯•é¡µé¢"""
    st.header("ğŸ§ª å¥åº·çŸ¥è¯†å°æµ‹éªŒ")
    extensions = HealthSystemExtensions(data)
    extensions.health_quiz()

# è¿è¡Œä¸»åº”ç”¨
if __name__ == "__main__":
    main_health_app()
